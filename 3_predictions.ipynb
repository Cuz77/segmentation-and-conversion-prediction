{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e097bd8",
   "metadata": {},
   "source": [
    "# Part 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c516891",
   "metadata": {},
   "source": [
    "This a a third and final part of the project. We already analyzed and pre-processed datasets, reduced dimentions using PCA method, and clusterized population. Here, we will predict the outcome of the mailing campaign using supervised learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361a9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import misc libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# import ML libraries\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07963b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train = pd.read_csv('dataset/mailout_train_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37881d9e",
   "metadata": {},
   "source": [
    "Before continuing with training the model, there's another concern we need to address. The class of interest is severely underrepresented.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9b780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42430\n",
       "1      532\n",
       "Name: RESPONSE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train['RESPONSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c48816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.987617\n",
       "1    0.012383\n",
       "Name: RESPONSE, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train['RESPONSE'].value_counts() / mailout_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fa5ca",
   "metadata": {},
   "source": [
    "There are three ways in which I'm going ot mitigate this issue. \n",
    "- resampling techniques (by resampling the majority class)\n",
    "- evaluation metrics (selecting scoring metrics which are not overly sensitive to this problem)\n",
    "- cost-sensitive training (using balanced class weights where possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21694ecd",
   "metadata": {},
   "source": [
    "The most crucial part is to choose between resampling methods. To make it easier, **undersample** approach has the following effects (converse to oversampling):\n",
    "- (advantage) we will make the training process faster and less resource-intensive\n",
    "- (advantage) we're reducing the risk of overfitting\n",
    "- (advantage) we might be reducing noise from irrelevant instances of the majority class\n",
    "- (disadvantage) we might be losing some important information since the imbalance is major and we will discard many instances\n",
    "\n",
    "Unfortunately, undersampling results in a small dataset that is not sufficient to train the model. So, I've decided to oversample the minoriy class instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156132aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mailout_train.drop(['RESPONSE'], axis=1)\n",
    "y = mailout_train['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d59553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled dataset shape: (84860, 438)\n",
      "Undersampled dataset shape: (1064, 438)\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X, y)\n",
    "\n",
    "print(f'Oversampled dataset shape: {X_oversampled.shape}')\n",
    "print(f'Undersampled dataset shape: {X_undersampled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb452c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: RESPONSE, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oversampled.value_counts() / y_oversampled.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc95b8",
   "metadata": {},
   "source": [
    "We don't have to split data into training and testing datasets since these files have been provided as a part of the task. Thus, we can jump to splitting features and target variable and trying out different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4963365",
   "metadata": {},
   "source": [
    "In order to establish the best model, it's important to select a proper scoring metric. It's always a matter of some trade-offs as no single metric can tell us anything about the problem. In this instance, we could consider several of them, for instance:\n",
    "\n",
    "\n",
    "1. Precision-recall curve plots the proportion of correctly predicted positives (precision) against the proportion of all positives predicted correctly (recall). Since it's focusing on the performance of imbalanced class, it would be suitable for our case. THe scoring metrics in the **average precision** that summarizes the precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight.\n",
    "\n",
    "\n",
    "2. The ROC curve plots the proportion of all positives predicted correctly (recall) against the false positive rate at various threshold settings. The final metric is the **area under the ROC curve**. It might not be the best for highly imbalanced datasets though.\n",
    "\n",
    "\n",
    "3. The F1 score measure the balance between precision and recall with the following formula:\n",
    "\n",
    "                2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    It is an improvement from simple accuracy but treats precision and recall equally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0b99b",
   "metadata": {},
   "source": [
    "We will opt in for the ROC AU metric since we've already addressed the imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17808ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_time(func):\n",
    "    '''\n",
    "    This is a decorator function that measures execution time of any other function.\n",
    "    '''\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # initialize time counter\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # execute finction\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        # calculate time passed\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        print(f\"Function {func.__name__} took {exec_time:.1f} seconds to execute\")\n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db52a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@exec_time\n",
    "def train_clf(clf, param_grid, X, y, verbose=0):\n",
    "    '''\n",
    "    Trains a model and returns best parameters\n",
    "    \n",
    "    INPUT:\n",
    "     - clf (classfier object): classfier to train on the data\n",
    "     - param_grid (dict): dictionary with tuning parameters\n",
    "     - X (dataframe): dataframe with features\n",
    "     - y (Series): array with target class labels\n",
    "    \n",
    "    OTPUT:\n",
    "     - Best estimator for the trained model\n",
    "    '''\n",
    "    \n",
    "    grid = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=verbose)\n",
    "    grid.fit(X, y)\n",
    "    print(f'Area under curve: {grid.best_score_}\\nbest params: {grid.best_params_}')\n",
    "    \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee43e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'),\n",
    "    'RandomForestClassifier': RandomForestClassifier(class_weight='balanced'), \n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'XGBClassifier': xgb.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad6f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "----------------------  Training LogisticRegression  ----------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.8159730179593467\n",
      "best params: {}\n",
      "Function train_clf took 1198.4 seconds to execute\n",
      "LogisticRegression(class_weight='balanced', max_iter=1000, solver='liblinear')\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "--------------------  Training RandomForestClassifier  --------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9936583839215235\n",
      "best params: {}\n",
      "Function train_clf took 174.5 seconds to execute\n",
      "RandomForestClassifier(class_weight='balanced')\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "------------------  Training GradientBoostingClassifier  ------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9046647723393967\n",
      "best params: {}\n",
      "Function train_clf took 671.8 seconds to execute\n",
      "GradientBoostingClassifier()\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "-------------------------  Training XGBClassifier  -------------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9930608351396477\n",
      "best params: {}\n",
      "Function train_clf took 30.2 seconds to execute\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# try several models\n",
    "for clf in models.keys():\n",
    "    space = (76 - len(f'  Training {clf}  ')) / 2\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print('-' * int(space) + f'  Training {clf}  ' + '-' * int(space))\n",
    "    print('----------------------------------------------------------------------------\\n')\n",
    "    print(train_clf(models[clf], {}, X_oversampled, y_oversampled))\n",
    "    print('\\n----------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dba5e4",
   "metadata": {},
   "source": [
    "Random Forest classifier and XGB classifier provide us with shockingly high ROC AUC scores strongly suggesting overfitting on the dataset. These algorithms will not generalize well on a new dataset. This is why we picked and the Gradient Boosting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbd5e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'GradientBoostingClassifier': {\n",
    "        'max_depth': [5, 7],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'n_estimators': [100, 200]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c015acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "------------------  Training GradientBoostingClassifier  ------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5; 1/8] START learning_rate=0.1, max_depth=5, n_estimators=100............\n",
      "[CV 1/5; 1/8] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.981 total time= 4.0min\n",
      "[CV 2/5; 1/8] START learning_rate=0.1, max_depth=5, n_estimators=100............\n",
      "[CV 2/5; 1/8] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.984 total time= 4.5min\n",
      "[CV 3/5; 1/8] START learning_rate=0.1, max_depth=5, n_estimators=100............\n",
      "[CV 3/5; 1/8] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.985 total time= 4.4min\n",
      "[CV 4/5; 1/8] START learning_rate=0.1, max_depth=5, n_estimators=100............\n",
      "[CV 4/5; 1/8] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.982 total time= 4.2min\n",
      "[CV 5/5; 1/8] START learning_rate=0.1, max_depth=5, n_estimators=100............\n",
      "[CV 5/5; 1/8] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.982 total time= 3.9min\n",
      "[CV 1/5; 2/8] START learning_rate=0.1, max_depth=5, n_estimators=200............\n",
      "[CV 1/5; 2/8] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.990 total time= 7.7min\n",
      "[CV 2/5; 2/8] START learning_rate=0.1, max_depth=5, n_estimators=200............\n",
      "[CV 2/5; 2/8] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.991 total time= 6.8min\n",
      "[CV 3/5; 2/8] START learning_rate=0.1, max_depth=5, n_estimators=200............\n",
      "[CV 3/5; 2/8] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.991 total time= 6.5min\n",
      "[CV 4/5; 2/8] START learning_rate=0.1, max_depth=5, n_estimators=200............\n",
      "[CV 4/5; 2/8] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.990 total time= 7.3min\n",
      "[CV 5/5; 2/8] START learning_rate=0.1, max_depth=5, n_estimators=200............\n",
      "[CV 5/5; 2/8] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.990 total time= 8.1min\n",
      "[CV 1/5; 3/8] START learning_rate=0.1, max_depth=7, n_estimators=100............\n",
      "[CV 1/5; 3/8] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.992 total time= 5.5min\n",
      "[CV 2/5; 3/8] START learning_rate=0.1, max_depth=7, n_estimators=100............\n",
      "[CV 2/5; 3/8] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.993 total time= 4.8min\n",
      "[CV 3/5; 3/8] START learning_rate=0.1, max_depth=7, n_estimators=100............\n",
      "[CV 3/5; 3/8] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.993 total time= 4.7min\n",
      "[CV 4/5; 3/8] START learning_rate=0.1, max_depth=7, n_estimators=100............\n",
      "[CV 4/5; 3/8] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.992 total time= 4.6min\n",
      "[CV 5/5; 3/8] START learning_rate=0.1, max_depth=7, n_estimators=100............\n",
      "[CV 5/5; 3/8] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.991 total time= 4.8min\n",
      "[CV 1/5; 4/8] START learning_rate=0.1, max_depth=7, n_estimators=200............\n",
      "[CV 1/5; 4/8] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.993 total time= 9.1min\n",
      "[CV 2/5; 4/8] START learning_rate=0.1, max_depth=7, n_estimators=200............\n",
      "[CV 2/5; 4/8] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.994 total time= 9.2min\n",
      "[CV 3/5; 4/8] START learning_rate=0.1, max_depth=7, n_estimators=200............\n",
      "[CV 3/5; 4/8] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.994 total time= 9.0min\n",
      "[CV 4/5; 4/8] START learning_rate=0.1, max_depth=7, n_estimators=200............\n",
      "[CV 4/5; 4/8] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.993 total time= 9.1min\n",
      "[CV 5/5; 4/8] START learning_rate=0.1, max_depth=7, n_estimators=200............\n",
      "[CV 5/5; 4/8] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.993 total time= 9.2min\n",
      "[CV 1/5; 5/8] START learning_rate=0.2, max_depth=5, n_estimators=100............\n",
      "[CV 1/5; 5/8] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.990 total time= 3.3min\n",
      "[CV 2/5; 5/8] START learning_rate=0.2, max_depth=5, n_estimators=100............\n",
      "[CV 2/5; 5/8] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.991 total time= 3.1min\n",
      "[CV 3/5; 5/8] START learning_rate=0.2, max_depth=5, n_estimators=100............\n",
      "[CV 3/5; 5/8] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.991 total time= 3.5min\n",
      "[CV 4/5; 5/8] START learning_rate=0.2, max_depth=5, n_estimators=100............\n",
      "[CV 4/5; 5/8] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.990 total time= 3.3min\n",
      "[CV 5/5; 5/8] START learning_rate=0.2, max_depth=5, n_estimators=100............\n",
      "[CV 5/5; 5/8] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.990 total time= 3.4min\n",
      "[CV 1/5; 6/8] START learning_rate=0.2, max_depth=5, n_estimators=200............\n",
      "[CV 1/5; 6/8] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.993 total time= 7.0min\n",
      "[CV 2/5; 6/8] START learning_rate=0.2, max_depth=5, n_estimators=200............\n",
      "[CV 2/5; 6/8] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.994 total time= 6.9min\n",
      "[CV 3/5; 6/8] START learning_rate=0.2, max_depth=5, n_estimators=200............\n",
      "[CV 3/5; 6/8] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.993 total time= 9.1min\n",
      "[CV 4/5; 6/8] START learning_rate=0.2, max_depth=5, n_estimators=200............\n",
      "[CV 4/5; 6/8] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.993 total time= 8.9min\n",
      "[CV 5/5; 6/8] START learning_rate=0.2, max_depth=5, n_estimators=200............\n",
      "[CV 5/5; 6/8] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.992 total time= 7.3min\n",
      "[CV 1/5; 7/8] START learning_rate=0.2, max_depth=7, n_estimators=100............\n",
      "[CV 1/5; 7/8] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.993 total time= 4.9min\n",
      "[CV 2/5; 7/8] START learning_rate=0.2, max_depth=7, n_estimators=100............\n",
      "[CV 2/5; 7/8] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.994 total time= 4.7min\n",
      "[CV 3/5; 7/8] START learning_rate=0.2, max_depth=7, n_estimators=100............\n",
      "[CV 3/5; 7/8] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.994 total time= 6.0min\n",
      "[CV 4/5; 7/8] START learning_rate=0.2, max_depth=7, n_estimators=100............\n",
      "[CV 4/5; 7/8] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.993 total time= 5.6min\n",
      "[CV 5/5; 7/8] START learning_rate=0.2, max_depth=7, n_estimators=100............\n",
      "[CV 5/5; 7/8] END learning_rate=0.2, max_depth=7, n_estimators=100;, score=0.993 total time= 5.0min\n",
      "[CV 1/5; 8/8] START learning_rate=0.2, max_depth=7, n_estimators=200............\n",
      "[CV 1/5; 8/8] END learning_rate=0.2, max_depth=7, n_estimators=200;, score=0.994 total time= 9.2min\n",
      "[CV 2/5; 8/8] START learning_rate=0.2, max_depth=7, n_estimators=200............\n",
      "[CV 2/5; 8/8] END learning_rate=0.2, max_depth=7, n_estimators=200;, score=0.994 total time= 9.2min\n",
      "[CV 3/5; 8/8] START learning_rate=0.2, max_depth=7, n_estimators=200............\n",
      "[CV 3/5; 8/8] END learning_rate=0.2, max_depth=7, n_estimators=200;, score=0.994 total time= 9.4min\n",
      "[CV 4/5; 8/8] START learning_rate=0.2, max_depth=7, n_estimators=200............\n",
      "[CV 4/5; 8/8] END learning_rate=0.2, max_depth=7, n_estimators=200;, score=0.993 total time= 9.4min\n",
      "[CV 5/5; 8/8] START learning_rate=0.2, max_depth=7, n_estimators=200............\n",
      "[CV 5/5; 8/8] END learning_rate=0.2, max_depth=7, n_estimators=200;, score=0.993 total time= 9.0min\n",
      "Area under curve: 0.993609497757852\n",
      "best params: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}\n",
      "Function train_clf took 16003.2 seconds to execute\n",
      "GradientBoostingClassifier(learning_rate=0.2, max_depth=7, n_estimators=200)\n",
      "\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# try several tuning parameters\n",
    "for clf in models.keys():\n",
    "    space = (76 - len(f'  Training {clf}  ')) / 2\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print('-' * int(space) + f'  Training {clf}  ' + '-' * int(space))\n",
    "    print('----------------------------------------------------------------------------\\n')\n",
    "    print(train_clf(models[clf], params[clf], X_oversampled, y_oversampled, verbose=10))\n",
    "    print('\\n----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac967fd",
   "metadata": {},
   "source": [
    "The final model will include the following parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67c0f1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.2, max_depth=7, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.2, max_depth=7, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, max_depth=7, n_estimators=200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.2, max_depth=7)\n",
    "gbclf.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4808538",
   "metadata": {},
   "source": [
    "Hypertuning might've caused the model to overfit though, so let's try our model on the original training set, without any resampling done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57483ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbclf.predict(X)\n",
    "confusion_matrix = metrics.confusion_matrix(preds, y)\n",
    "mtx_pct = confusion_matrix / confusion_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bdcbaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41457,    44],\n",
       "       [  973,   488]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e178595",
   "metadata": {},
   "source": [
    "Thankfully, the model did not predict all instances for the majority class. While 96% of predictions were assigned to it, it's pretty close to the actual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "611e3fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96496904, 0.00102416],\n",
       "       [0.02264792, 0.01135888]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e40e614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.matshow(mtx_pct, cmap='copper')\n",
    "\n",
    "for i in [0, 1]:\n",
    "    for j in [0, 1]:\n",
    "        ax.text(i-0.09, j+0.02, np.round(mtx_pct[j][i], 2), color='white', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017c0a5",
   "metadata": {},
   "source": [
    "Interestingly, the F1 score is pretty low due to imbalance, since recall might not be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b9a6836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.49\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 score: {np.round(metrics.f1_score(preds, y), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81145002",
   "metadata": {},
   "source": [
    "Normally, we would test the data on the test dataset. However, the dataset for this assignment is hidden and the part of the competition is to submit the result not knowing how it performs on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ffe1b",
   "metadata": {},
   "source": [
    "For future improvements, several avenues can be explored. First, experimenting with alternative machine learning models and ensemble methods could potentially enhance predictive accuracy and generalizability, especially favoring recall. Additionally, a thorough review of the demographic and behavioral data might reveal deeper insights into customer preferences and motivations and ultimately might result in discarding features introducing noise into data. A more granular tuning process could be employed with more processing resources available. Finally, implementing a continuous feedback loop where the model's predictions are regularly updated with new campaign data could also refine its predictive capabilities over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a117e4e",
   "metadata": {},
   "source": [
    "And with that, the project is complete. An overview of the project has been provided in the attached article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e76881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
