{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e097bd8",
   "metadata": {},
   "source": [
    "# Part 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c516891",
   "metadata": {},
   "source": [
    "This a a third and final part of the project. We already analyzed and pre-processed datasets, reduced dimentions using PCA method, and clusterized population. Here, we will predict the outcome of the mailing campaign using supervised learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361a9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import misc libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# import ML libraries\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c918a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load population clusters\n",
    "azdias_clustered = pd.read_pickle('azdias_clustered.pkl')\n",
    "customers_clustered = pd.read_pickle('azdias_clustered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07963b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train = pd.read_csv('dataset/mailout_train_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37881d9e",
   "metadata": {},
   "source": [
    "Before continuing with training the model, there's another concern we need to address. The class of interest is severely underrepresented.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9b780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42430\n",
       "1      532\n",
       "Name: RESPONSE, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train['RESPONSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c48816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.987617\n",
       "1    0.012383\n",
       "Name: RESPONSE, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train['RESPONSE'].value_counts() / mailout_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fa5ca",
   "metadata": {},
   "source": [
    "There are three ways in which I'm going ot mitigate this issue. \n",
    "- resampling techniques (by resampling the majority class)\n",
    "- evaluation metrics (selecting scoring metrics which are not overly sensitive to this problem)\n",
    "- cost-sensitive training (using balanced class weights where possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21694ecd",
   "metadata": {},
   "source": [
    "The most crucial part is to choose between resampling methods. To make it easier, **undersample** approach has the following effects (converse to oversampling):\n",
    "- (advantage) we will make the training process faster and less resource-intensive\n",
    "- (advantage) we're reducing the risk of overfitting\n",
    "- (advantage) we might be reducing noise from irrelevant instances of the majority class\n",
    "- (disadvantage) we might be losing some important information since the imbalance is major and we will discard many instances\n",
    "\n",
    "Unfortunately, undersampling results in a small dataset that is not sufficient to train the model. So, I've decided to oversample the minoriy class instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156132aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mailout_train.drop(['RESPONSE'], axis=1)\n",
    "y = mailout_train['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00d59553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: (84860, 438)\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X, y)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X, y)\n",
    "# X_resampled = resample(X, replace=True, n_samples=42430)\n",
    "# y_resampled = resample(y, replace=True, n_samples=42430)\n",
    "\n",
    "# X_resampled, y_resampled = resample(X[y == 1],\n",
    "#                                     y[y == 1],\n",
    "#                                     replace=True,\n",
    "#                                     n_samples=42430,\n",
    "#                                     random_state=42)\n",
    "\n",
    "# X_balanced = np.vstack((X[y == 0], X_resampled))\n",
    "# y_balanced = np.hstack((y[y == 0], y_resampled))\n",
    "\n",
    "print(f'Oversampled dataset shape: {X_oversampled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e1a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled dataset shape: (1064, 438)\n"
     ]
    }
   ],
   "source": [
    "print(f'Undersampled dataset shape: {X_undersampled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cb452c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: RESPONSE, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oversampled.value_counts() / y_oversampled.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc95b8",
   "metadata": {},
   "source": [
    "We don't have to split data into training and testing datasets since these files have been provided as a part of the task. Thus, we can jump to splitting features and target variable and trying out different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4963365",
   "metadata": {},
   "source": [
    "In order to establish the best model, it's important to select a proper scoring metric. It's always a matter of some trade-offs as no single metric can tell us anything about the problem. In this instance, we could consider several of them, for instance:\n",
    "\n",
    "\n",
    "1. Precision-recall curve plots the proportion of correctly predicted positives (precision) against the proportion of all positives predicted correctly (recall). Since it's focusing on the performance of imbalanced class, it would be suitable for our case. THe scoring metrics in the **average precision** that summarizes the precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight.\n",
    "\n",
    "\n",
    "2. The ROC curve plots the proportion of all positives predicted correctly (recall) against the false positive rate at various threshold settings. The final metric is the **area under the ROC curve**. It might not be the best for highly imbalanced datasets though.\n",
    "\n",
    "\n",
    "3. The F1 score measure the balance between precision and recall with the following formula:\n",
    "\n",
    "                2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    It is an improvement from simple accuracy but treats precision and recall equally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0b99b",
   "metadata": {},
   "source": [
    "We will opt in for the ROC AU metric since we've already addressed the imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e17808ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_time(func):\n",
    "    '''\n",
    "    This is a decorator function that measures execution time of any other function.\n",
    "    '''\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # initialize time counter\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # execute finction\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        # calculate time passed\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        print(f\"Function {func.__name__} took {exec_time:.1f} seconds to execute\")\n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1db52a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@exec_time\n",
    "def train_clf(clf, param_grid, X, y):\n",
    "    '''\n",
    "    Trains a model and returns best parameters\n",
    "    \n",
    "    INPUT:\n",
    "     - clf (classfier object): classfier to train on the data\n",
    "     - param_grid (dict): dictionary with tuning parameters\n",
    "     - X (dataframe): dataframe with features\n",
    "     - y (Series): array with target class labels\n",
    "    \n",
    "    OTPUT:\n",
    "     - Best estimator for the trained model\n",
    "    '''\n",
    "    \n",
    "    grid = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "    grid.fit(X, y)\n",
    "    print(f'Area under curve: {grid.best_score_}\\nbest params: {grid.best_params_}')\n",
    "    \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee43e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'),\n",
    "    'RandomForestClassifier': RandomForestClassifier(class_weight='balanced'), \n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'XGBClassifier': xgb.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ad6f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "----------------------  Training LogisticRegression  ----------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.8159730179593467\n",
      "best params: {}\n",
      "Function train_clf took 1301.0 seconds to execute\n",
      "LogisticRegression(class_weight='balanced', max_iter=1000, solver='liblinear')\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "--------------------  Training RandomForestClassifier  --------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9936581200773269\n",
      "best params: {}\n",
      "Function train_clf took 206.5 seconds to execute\n",
      "RandomForestClassifier(class_weight='balanced')\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "------------------  Training GradientBoostingClassifier  ------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9046671524917806\n",
      "best params: {}\n",
      "Function train_clf took 695.6 seconds to execute\n",
      "GradientBoostingClassifier()\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "-------------------------  Training XGBClassifier  -------------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9930608351396477\n",
      "best params: {}\n",
      "Function train_clf took 26.3 seconds to execute\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# try several models\n",
    "for clf in models.keys():\n",
    "    space = (76 - len(f'  Training {clf}  ')) / 2\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print('-' * int(space) + f'  Training {clf}  ' + '-' * int(space))\n",
    "    print('----------------------------------------------------------------------------\\n')\n",
    "    print(train_clf(models[clf], {}, X_oversampled, y_oversampled))\n",
    "    print('\\n----------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dba5e4",
   "metadata": {},
   "source": [
    "RandomForestClassifier and Y provide us with a shocklingly high ROC AUC strongly suggesting overfitting on overbalanced dataset. These algorithms will not generalize well on a new dataset. This is why we're choosing to pick and tune the GradientBoosting classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbd5e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#     'LogisticRegression': {\n",
    "#         'C': [0.1, 1],\n",
    "#         'penalty': ['l1', 'l2']\n",
    "#     },\n",
    "#     'RandomForestClassifier': {\n",
    "#         'n_estimators': [50, 100, 150],\n",
    "#         'max_depth': [None, 10, 20],\n",
    "#         'min_samples_split': [2, 5, 10],\n",
    "#         'max_features': ['sqrt', 'log2']\n",
    "#     },\n",
    "#     'GradientBoostingClassifier': {\n",
    "#         'max_depth': [3, 5, 7],\n",
    "#         'learning_rate': [0.1, 0.01, 0.001],\n",
    "#         'subsample': [0.5, 0.7, 1]                         \n",
    "#     },\n",
    "    'XGBClassifier': {\n",
    "        'max_depth': [5, 10, 20],\n",
    "        'n_estimators': [140, 200, 250],\n",
    "        'learning_rate': [0.1, 0.2]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5801de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'XGBClassifier': xgb.XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c015acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "-------------------------  Training XGBClassifier  -------------------------\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Area under curve: 0.9936072731346786\n",
      "best params: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200}\n",
      "Function train_clf took 925.1 seconds to execute\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# try several models\n",
    "for clf in models.keys():\n",
    "    space = (76 - len(f'  Training {clf}  ')) / 2\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print('-' * int(space) + f'  Training {clf}  ' + '-' * int(space))\n",
    "    print('----------------------------------------------------------------------------\\n')\n",
    "    print(train_clf(models[clf], params[clf], X_oversampled, y_oversampled))\n",
    "    print('\\n----------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67c0f1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=2, max_features=2, n_estimators=60)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=2, max_features=2, n_estimators=60)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2, max_features=2, n_estimators=60)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators=60, learning_rate=0.1, max_features=2, max_depth=2)\n",
    "gbclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57483ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbclf.predict(X)\n",
    "confusion_matrix = metrics.confusion_matrix(preds, y)\n",
    "mtx_pct = confusion_matrix / confusion_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bdcbaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42430,   531],\n",
       "       [    0,     1]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "611e3fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.87616964e-01, 1.23597598e-02],\n",
       "       [0.00000000e+00, 2.32763838e-05]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e40e614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD8CAYAAACvvuKtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMaklEQVR4nO3bfWxV9R3H8c+v3OtUUJhU2qKt9WnWhwWFSgRKl80206hzkKxzugxnkcJ8wuwfo/tDY6KYTEESEykLUpNF4+LDfGCjbGNzsUV7u0wFH2opCBVb7BBsKaX3wm9/nNpy8ZbbQm+v/d73K7kh93d/5/A7Ob57bs9B570XADuy0r0AACOLqAFjiBowhqgBY4gaMIaoAWOIegicc9c45z52zjU75+5L93qQnHNujXNut3Nuc7rXMtqIOgnn3DhJT0m6VtIlkn7hnLskvavCEKyVdE26F5EORJ3cTEnN3vsW732vpOcl3ZjmNSEJ7/2bkvakex3pQNTJnSVp5xHvW/vGgG8logaMIerkPpOUf8T7s/vGgG8lok6uQdKFzrlznXMnSbpJ0qtpXhMwKKJOwnsfk3SnpPWSPpT0gvd+S3pXhWScc89Jqpd0kXOu1TlXme41jRbH/3oJ2MKVGjCGqAFjiBowhqgBY4gaMIaoh8E5tyjda8DwZOI5I+rhybj/QAzIuHNG1IAxKfnHJ9mTTvWFeZNGfL/p9sXebp056dR0LyMlGj/6PN1LwDB5712i8VAq/rLCvEmKPHN7KnaNFAnNeTjdS8AwHDo8+MWYr9+AMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEfbScK6XLl0ozfyddViWdVpBk/kxp2p3B/Gl3SdnT4j93WdJZP5AuvyeY8/0l0sQLUrb8TLR48RJ90rxVXfu79fY7DSopKTnm/NLSUr39ToO69ner6ZNmLaqqivt87ty5evmVV/Tpjp2KHTqsXy1YkMrljziiPtLkS6VzrpV2/Vt672mpa6dU9EvppImJ5+dcKRWUSa3/lN59SmrdKJ17nTTpewNz8q8O5m1fF8zZHZEuukk6NXdUDsm6n1VUaPmKFVq27FEVz5iu+vp6vf7GOuXn5yecX1hYqNdef0P19fUqnjFdjz22TE8+uVLz5s/vnzNhwgRt2bxF9967VN3d3aN1KCPGee9HfKfFF0/1kWduH/H9ptxlt0v726Vtrw6MTbtb2vOBtPNv35x/aaXU9Zn06V8Hxgp+LE04S/pgTfB++m+lXW9JbZsG5lz4c+lwVNr6UmqO4ziE5jyc7iUcl7q6er33/vtaXLWof+zDjz7WSy++qAceuP8b8x99dJl+Om+eLi66qH9sVfVqXXrJJSopmfON+Xv3faW7775Lz9bUpOYAjtOhw17ee5foM67UX3PjpPF50r7m+PF9W6XTEv/UlwtJh2PxY4ejQdQu69hzTk/ytR5JhcNhTZ8xQxs21MaNb9iwQbNmzUq4zVVXXaUNGzbEjdXWrteM4mKFQqGUrXU0DSlq59w1zrmPnXPNzrn7Ur2otAidGoQd3R8/Hu2SwhMSb7OvWTrzCmn81OD9+KnSlOlSVijY39dz8q6STp4syUkTz5POuFgKn5ayQ8kU2dnZCoVC2t3eHje+u71dObmJf73Jyc1NOD8cDis7Oztlax1NSX80OefGSXpKUrmkVkkNzrlXvfcfpHpx33qt/wqCv3Sh5BT8QOh4V5paIqnv15rtf5HO+0lwM01e6vlS+uK/0pQr0rdumDaU7xszJTV771skyTn3vKQbJdmKOtYt+UNSeHz8eHhCcLVOxMeklj9L214L5vV2SjnFUqxHinYP7Lfp+eBreOgUKdopFZQHceOEdHR0KBaLaUpOTtz4lJwctbe1Jdymva0t4fxoNKqOjo6UrXU0DeXr91mSdh7xvrVvLI5zbpFzLuKci3yxd+zdMZQ/JO3/XJp4fvz4xPOkzp2Jt+nf9rDU+5UkL02+TNrbpP4rdf+cWBC0ywq+fn/50UiuPiNFo1H9p7FRZWXlceNlZWWqr69PuM2mTZtUVlZ21PxyNUYiisViCbcZa0bszoD3vlpStRTc/R6p/Y6qz+uk8+cHd7Q7dwSPok46TWpvCD4/f17w59aXgz9PnhzcFOtqlcadIuXNkk6ZMvC5FHwePl3qbgv2dfYPJbngjjhO2PIVy1VT86waGt5R3VtvaVHVYk2dOlWrVj0tSXpm7VpJ0q9vvVWStGrV0/rNHXfo8SeWa3X1Ks2eM0cLFizQLbfc3L/P8ePH64ILgn9LkJWVpYL8Ak2bNk179uzRzp1JfsB/Cwwl6s8kHXn79+y+MXv+tyW4wXV2aXAjq3u39NEfpd59weffOfp5tZPyZgdx+8PSV9ukLX+QDu49YkpIyv+RdPJ3pUO90t5PpOaXpEM9o3VUpv3phRc0+YzJuv/+B5SXl6fNmzfrhuuv044dOyRJBfnxTxm2b9+uG66/Tr9//AktXrxYu3bt0tKl9+jllwYeLxYXF+vv/9jY//7Bhx7Sgw89pJqataq87bbRObATkPQ5tXMuJKlJ0tUKYm6QdLP3fstg24zZ59QZbKw+p85Ux3pOnfRK7b2POefulLRe0jhJa44VNID0GtLv1N77dZLWpXgtAEYA/6IMMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY5z3fuR36tzI7xRAHO+9SzTOlRowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOIGjCGqAFjiBowhqgBY4gaMIaoAWOI+ihLlixRS0uLDhw4oEgkopKSkmPOLy0tVSQS0YEDB7R161ZVVVWN0krxNc7ZUbz3I/6S5Mfiq6Kiwvf29vqFCxf6oqIiv3LlSt/Z2enz8/MTzi8sLPRdXV1+5cqVvqioyC9cuND39vb6+fPnp/1YMuWVyeds0P6IeuC1adMmX11dHTfW1NTkH3nkkYTzly1b5puamuLGVq9e7evq6tJ+LJnyyuRzNlh/fP3uEw6HNWPGDNXW1saN19bWavbs2Qm3mTVr1jfmr1+/XsXFxQqFQilbKwKcs8SSRu2cW+Oc2+2c2zwaC0qX7OxshUIhtbe3x423t7crNzc34Ta5ubkJ54fDYWVnZ6dsrQhwzhIbypV6raRrUrwOACMkadTe+zcl7RmFtaRVR0eHYrGYcnJy4sZzcnLU1taWcJu2traE86PRqDo6OlK2VgQ4Z4nxO3WfaDSqxsZGlZeXx42Xl5errq4u4Tb19fUJ50ciEcVisZStFQHO2SCGeDe7UNLmJHMWSYr0vdJ+Z/B4XhUVFf7gwYO+srLSFxUV+RUrVvjOzk5fUFDgJfmamhpfU1PTP//rxyPLly/3RUVFvrKy0h88eHBMPh4Zq69MPmcn9EhLQ4jawiMtSX7JkiV+27Ztvqenx0ciET937tz+zzZu3Og3btwYN7+0tNQ3Njb6np4e39LS4quqqtJ+DJn2ytRzNlh/ri/CY3LOFUp63Xt/WdLJwfzkOwVwQrz3LtH4UB5pPSepXtJFzrlW51zlSC8OwMgZ0pV62DvlSg2k3HFfqQGMLUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMUQNGEPUgDFEDRhD1IAxRA0YQ9SAMaEU7bdD0qcp2nc6ZSs4NowdVs/ZOYN94Lz3o7mQMc05F/HeF6d7HRi6TDxnfP0GjCFqwBiiHp7qdC8Aw5Zx54zfqQFjuFIDxhA1YAxRA8YQNWAMUQPG/B++LCCt7lspYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.matshow(mtx_pct, cmap='copper')\n",
    "\n",
    "for i in [0, 1]:\n",
    "    for j in [0, 1]:\n",
    "        ax.text(i-0.09, j+0.02, np.round(mtx_pct[j][i], 2), color='white', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a6836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1 score: {np.round(metrics.f1_score(preds, y_undersampled), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6a136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e267979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
